<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="ej9QS5Et7hE3BmLZiG52EKZZx93xiDvuUVbZ_-HC6ac"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Machine Learning Potentials | Christoph Schran</title> <meta name="author" content="Christoph Schran"> <meta name="description" content="Learning structure-energy relations"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://cschran.github.io/projects/1_project/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Christoph </span>Schran</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Machine Learning Potentials</h1> <p class="post-description">Learning structure-energy relations</p> </header> <article> <p>Machine learning in computational chemistry has emerged as an indispensable driving force for innovation. By combining the low cost of traditional empirical potentials with the accuracy of ab initio methods, machine learning potentials deliver long time and large length scales required for insight into complex molecular systems. Instead of physically motivated forms of interactions, the structure-energy relation is represented by highly flexible mathematical functions, such as neural networks or kernel based approaches, which are trained to reproduce high level reference calculations. Main challenges in the field are the generation of robust and accurate models, but also the construction of representative training data. Our group uses neural network based approaches and has a strong background in automating the generation of training data to provide robust models.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mlp-nnp-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mlp-nnp-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mlp-nnp-1400.webp"></source> <img src="/assets/img/mlp-nnp.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mlp-project-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mlp-project-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mlp-project-1400.webp"></source> <img src="/assets/img/mlp-project.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mlp-QbC-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mlp-QbC-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mlp-QbC-1400.webp"></source> <img src="/assets/img/mlp-QbC.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Overview of the machine learning approaches used in our research. Left: Aritecture of neural network potentials. Middle: Schematics of committee neural network potentials. Right: Concept of the active learning technique query by committee. </div> <p>The recent advances in the field of machine learning potentials have only now opened up the door to investigate many challenging phenomena with great prospect for future work.</p> <div class="publications"> <h2>Selected Publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/ph2-int.png"></div> <div id="Duran2022/10.1063/5.0100953" class="col-sm-8"> <div class="title">Neural Network Interaction Potentials for para-Hydrogen with Flexible Molecules</div> <div class="author"> Laura Durán Caballero, <em>Christoph Schran</em>, Fabien Brieuc, and <a href="https://www.theochem.ruhr-uni-bochum.de/allcategories-en-gb/research/marx/researchmarx" rel="external nofollow noopener" target="_blank">Dominik Marx</a> </div> <div class="periodical"> <em>J. Chem. Phys.</em>, Aug 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2206.08251" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aip.scitation.org/doi/abs/10.1063/5.0100953" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script><div data-doi="10.1063/5.0100953" class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-popover="right" data-badge-type="2" style="display:inline"></div> </div> <div class="abstract hidden"> <p>The study of molecular impurities in para-hydrogen (pH2) clusters is key to push forward our understanding of intra- and intermolecular interactions including their impact on the superfluid response of this bosonic quantum solvent. This includes tagging with one or very few pH2, the microsolvation regime, and matrix isolation. However, the fundamental coupling between the bosonic pH2 environment and the (ro-)vibrational motion of molecular impurities remains poorly understood. Quantum simulations can in provide the necessary atomistic insight, but very accurate descriptions of the involved interactions are required. Here, we present a data-driven approach for the generation of impurity-pH2 interaction potentials based on machine learning techniques which retain the full flexibility of the impurity. We employ the well-established adiabatic hindered rotor (AHR) averaging technique to include the impact of the nuclear spin statistics on the symmetry-allowed rotational quantum numbers of pH2. Embedding this averaging procedure within the high-dimensional neural network potential (NNP) framework enables the generation of highly-accurate AHR-averaged NNPs at coupled cluster accuracy, namely CCSD(T*)-F12a/aVTZcp in an automated manner. We apply this methodology to the water and protonated water molecules, as representative cases for quasi-rigid and highly-flexible molecules respectively, and obtain AHR-averaged NNPs that reliably describe the H2O-pH2 and H3O+-pH2 interactions. Using path integral simulations we show for the hydronium cation that umbrella-like tunneling inversion has a strong impact on the first and second pH2 microsolvation shells. The data-driven nature of our protocol opens the door to the study of bosonic pH2 quantum solvation for a wide range of embedded impurities.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Duran2022/10.1063/5.0100953</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{Dur{\'{a}}n Caballero}, Laura and Schran, Christoph and Brieuc, Fabien and Marx, Dominik}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1063/5.0100953}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2206.08251}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0021-9606}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{J. Chem. Phys.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{074302}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{AIP Publishing LLCAIP Publishing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Neural Network Interaction Potentials for para-Hydrogen with Flexible Molecules}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{157}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/nn-dms.png"></div> <div id="Beckmann2022/10.1021/ACS.JCTC.2C00511" class="col-sm-8"> <div class="title">Infrared spectra at coupled cluster accuracy from neural network representations</div> <div class="author"> Richard Beckmann, Fabien Brieuc, <em>Christoph Schran</em>, and <a href="https://www.theochem.ruhr-uni-bochum.de/allcategories-en-gb/research/marx/researchmarx" rel="external nofollow noopener" target="_blank">Dominik Marx</a> </div> <div class="periodical"> <em>J. Chem. Theory Comput.</em>, Aug 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2202.00303" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://pubs.acs.org/doi/full/10.1021/acs.jctc.2c00511" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script><div data-doi="10.1021/ACS.JCTC.2C00511" class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-popover="right" data-badge-type="2" style="display:inline"></div> </div> <div class="abstract hidden"> <p>Infrared spectroscopy is key to elucidate molecular structures, monitor reactions and observe conformational changes, while providing information on both structural and dynamical properties. This makes the accurate prediction of infrared spectra based on first-principle theories a highly desirable pursuit. Molecular dynamics simulations have proven to be a particularly powerful approach for this task, albeit requiring the computation of energies, forces and dipole moments for a large number of molecular configurations as a function of time. This explains why highly accurate first principles methods, such as coupled cluster theory, have so far been inapplicable for the prediction of fully anharmonic vibrational spectra of large systems at finite temperatures. Here, we push cutting-edge machine learning techniques forward by using neural network representations of energies, forces and in particular dipoles to predict such infrared spectra fully at "gold standard" coupled cluster accuracy as demonstrated for protonated water clusters as large as the protonated water hexamer, in its extended Zundel configuration. Furthermore, we show that this methodology can be used beyond the scope of the data considered during the development of the neural network models, allowing for the computation of finite-temperature infrared spectra of large systems inaccessible to explicit coupled cluster calculations. This substantially expands the hitherto existing limits of accuracy, speed and system size for theoretical spectroscopy and opens up a multitude of avenues for the prediction of vibrational spectra and the understanding of complex intra- and intermolecular couplings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Beckmann2022/10.1021/ACS.JCTC.2C00511</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Beckmann, Richard and Brieuc, Fabien and Schran, Christoph and Marx, Dominik}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1021/ACS.JCTC.2C00511}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2202.00303}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1549-9618}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{J. Chem. Theory Comput.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{American Chemical Society}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/simple-mlp.png"></div> <div id="Schran2021/10.1073/PNAS.2110077118" class="col-sm-8"> <div class="title">Machine learning potentials for complex aqueous systems made simple</div> <div class="author"> <em>Christoph Schran</em>, Fabian L. Thiemann, Patrick Rowe, Erich A. Müller, <a href="https://scholar.google.com/citations?user=EcEE4CAAAAAJ&amp;hl=de" rel="external nofollow noopener" target="_blank">Ondrej Marsalek</a>, and <a href="https://www.ch.cam.ac.uk/person/am452" rel="external nofollow noopener" target="_blank">Angelos Michaelides</a> </div> <div class="periodical"> <em>Proc. Natl. Acad. Sci.</em>, Sep 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2106.00048" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.pnas.org/content/118/38/e2110077118" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/MarsalekGroup/aml" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script><div data-doi="10.1073/PNAS.2110077118" class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-popover="right" data-badge-type="2" style="display:inline"></div> </div> <div class="abstract hidden"> <p>Simulation techniques based on accurate and efficient representations of potential energy surfaces are urgently needed for the understanding of complex aqueous systems such as solid-liquid interfaces. Here, we present a machine learning framework that enables the efficient development and validation of models for complex aqueous systems. Instead of trying to deliver a globally-optimal machine learning potential, we propose to develop models applicable to specific thermodynamic state points in a simple and user-friendly process. After an initial ab initio simulation, a machine learning potential is constructed with minimum human effort through a data-driven active learning protocol. Such models can afterwards be applied in exhaustive simulations to provide reliable answers for the scientific question at hand. We showcase this methodology on a diverse set of aqueous systems with increasing degrees of complexity. The systems chosen here comprise water with different ions in solution, water on a titanium dioxide surface, as well as water confined in nanotubes and between molybdenum disulfide sheets. Highlighting the accuracy of our approach compared to the ab initio reference, the resulting models are evaluated in detail with an automated validation protocol that includes structural and dynamical properties and the precision of the force prediction of the models. Finally, we demonstrate the capabilities of our approach for the description of water on the rutile titanium dioxide (110) surface to analyze structure and mobility of water on this surface. Such machine learning models provide a straightforward and uncomplicated but accurate extension of simulation time and length scales for complex systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Schran2021/10.1073/PNAS.2110077118</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schran, Christoph and Thiemann, Fabian L. and Rowe, Patrick and M{\"{u}}ller, Erich A. and Marsalek, Ondrej and Michaelides, Angelos}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1073/PNAS.2110077118}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0027-8424}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. Natl. Acad. Sci.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{38}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{e2110077118}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{National Academy of Sciences}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{118}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/trans-nnp.jpg"></div> <div id="Schran2021/10.1063/5.0035438" class="col-sm-8"> <div class="title">Transferability of machine learning potentials: Protonated water neural network potential applied to the protonated water hexamer</div> <div class="author"> <em>Christoph Schran</em>, Fabien Brieuc, and <a href="https://www.theochem.ruhr-uni-bochum.de/allcategories-en-gb/research/marx/researchmarx" rel="external nofollow noopener" target="_blank">Dominik Marx</a> </div> <div class="periodical"> <em>J. Chem. Phys.</em>, Feb 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2010.15177" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aip.scitation.org/doi/full/10.1063/5.0035438" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script><div data-doi="10.1063/5.0035438" class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-popover="right" data-badge-type="2" style="display:inline"></div> </div> <div class="abstract hidden"> <p>A previously published neural network potential for the description of protonated water clusters up to the protonated water tetramer, H+(H2O)4, at an essentially converged coupled cluster accuracy [C. Schran, J. Behler, and D. Marx, J. Chem. Theory Comput. 16, 88 (2020)] is applied to the protonated water hexamer, H+(H2O)6 - a system that the neural network has never seen before. Although being in the extrapolation regime, it is shown that the potential not only allows for quantum simulations from ultra-low temperatures ∼1 K up to 300 K but is also able to describe the new system very accurately compared to explicit coupled cluster calculations. This transferability of the model is rationalized by the similarity of the atomic environments encountered for the larger cluster compared to the environments in the training set of the model. Compared to the interpolation regime, the quality of the model is reduced by roughly one order of magnitude, but most of the difference to the coupled cluster reference comes from global shifts of the potential energy surface, while local energy fluctuations are well recovered. These results suggest that the application of neural network potentials in extrapolation regimes can provide useful results and might be more general than usually thought.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Schran2021/10.1063/5.0035438</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schran, Christoph and Brieuc, Fabien and Marx, Dominik}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1063/5.0035438}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{10897690}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{J. Chem. Phys.}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{051101}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Transferability of machine learning potentials: Protonated water neural network potential applied to the protonated water hexamer}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{154}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/cnnp.png"></div> <div id="Schran2020/10.1063/5.0016004" class="col-sm-8"> <div class="title">Committee neural network potentials control generalization errors and enable active learning</div> <div class="author"> <em>Christoph Schran</em>, Krystof Brezina, and <a href="https://scholar.google.com/citations?user=EcEE4CAAAAAJ&amp;hl=de" rel="external nofollow noopener" target="_blank">Ondrej Marsalek</a> </div> <div class="periodical"> <em>J. Chem. Phys.</em>, Sep 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2006.01541" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://aip.scitation.org/doi/10.1063/5.0016004" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script><div data-doi="10.1063/5.0016004" class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-popover="right" data-badge-type="2" style="display:inline"></div> </div> <div class="abstract hidden"> <p>It is well known in the field of machine learning that committee models improve accuracy, provide generalization error estimates, and enable active learning strategies. In this work, we adapt these concepts to interatomic potentials based on artificial neural networks. Instead of a single model, multiple models that share the same atomic environment descriptors yield an average that outperforms its individual members as well as a measure of the generalization error in the form of the committee disagreement. We not only use this disagreement to identify the most relevant configurations to build up the model’s training set in an active learning procedure but also monitor and bias it during simulations to control the generalization error. This facilitates the adaptive development of committee neural network potentials and their training sets while keeping the number of ab initio calculations to a minimum. To illustrate the benefits of this methodology, we apply it to the development of a committee model for water in the condensed phase. Starting from a single reference ab initio simulation, we use active learning to expand into new state points and to describe the quantum nature of the nuclei. The final model, trained on 814 reference calculations, yields excellent results under a range of conditions, from liquid water at ambient and elevated temperatures and pressures to different phases of ice, and the air-water interface - all including nuclear quantum effects. This approach to committee models will enable the systematic development of robust machine learning models for a broad range of systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Schran2020/10.1063/5.0016004</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schran, Christoph and Brezina, Krystof and Marsalek, Ondrej}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1063/5.0016004}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2006.01541}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{10897690}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{J. Chem. Phys.}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{104105}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Committee neural network potentials control generalization errors and enable active learning}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{153}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/automated-nnp.png"></div> <div id="Schran2020/10.1021/acs.jctc.9b00805" class="col-sm-8"> <div class="title">Automated Fitting of Neural Network Potentials at Coupled Cluster Accuracy: Protonated Water Clusters as Testing Ground</div> <div class="author"> <em>Christoph Schran</em>, <a href="https://www.uni-goettingen.de/de/556198.html" rel="external nofollow noopener" target="_blank">Jörg Behler</a>, and <a href="https://www.theochem.ruhr-uni-bochum.de/allcategories-en-gb/research/marx/researchmarx" rel="external nofollow noopener" target="_blank">Dominik Marx</a> </div> <div class="periodical"> <em>J. Chem. Theory Comput.</em>, Jan 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/1908.08734" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://pubs.acs.org/doi/10.1021/acs.jctc.9b00805" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script><div data-doi="10.1021/acs.jctc.9b00805" class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-popover="right" data-badge-type="2" style="display:inline"></div> </div> <div class="abstract hidden"> <p>Highly accurate potential energy surfaces are of key interest for the detailed understanding and predictive modeling of chemical systems. In recent years, several new types of force fields, which are based on machine learning algorithms and fitted to ab initio reference calculations, have been introduced to meet this requirement. Here, we show how high-dimensional neural network potentials can be employed to automatically generate the potential energy surface of finite sized clusters at coupled cluster accuracy, namely CCSD(T*)-F12a/aug-cc-pVTZ. The developed automated procedure utilizes the established intrinsic properties of the model such that the configurations for the training set are selected in an unbiased and efficient way to minimize the computational effort of expensive reference calculations. These ideas are applied to protonated water clusters from the hydronium cation, H3O+, up to the tetramer, H9O4+, and lead to a single potential energy surface that describes all these systems at essentially converged coupled cluster accuracy with a fitting error of 0.06 kJ/mol per atom. The fit is validated in detail for all clusters up to the tetramer and yields reliable results not only for stationary points but also for reaction pathways and intermediate configurations as well as different sampling techniques. Per design, the neural network potentials (NNPs) constructed in this fashion can handle very different conditions including the quantum nature of the nuclei and enhanced sampling techniques covering very low as well as high temperatures. This enables fast and exhaustive exploration of the targeted protonated water clusters with essentially converged interactions. In addition, the automated process will allow one to tackle finite systems much beyond the present case.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Schran2020/10.1021/acs.jctc.9b00805</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schran, Christoph and Behler, J{\"{o}}rg and Marx, Dominik}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1021/acs.jctc.9b00805}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{15499626}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{J. Chem. Theory Comput.}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{88--99}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/he-int-nnp.png"></div> <div id="Schran2018/10.1063/1.4996819" class="col-sm-8"> <div class="title">High-dimensional neural network potentials for solvation: The case of protonated water clusters in helium</div> <div class="author"> <em>Christoph Schran</em>, Felix Uhl, <a href="https://www.uni-goettingen.de/de/556198.html" rel="external nofollow noopener" target="_blank">Jörg Behler</a>, and <a href="https://www.theochem.ruhr-uni-bochum.de/allcategories-en-gb/research/marx/researchmarx" rel="external nofollow noopener" target="_blank">Dominik Marx</a> </div> <div class="periodical"> <em>J. Chem. Phys.</em>, Mar 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dx.doi.org/10.1063/1.4996819" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script><div data-doi="10.1063/1.4996819" class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-popover="right" data-badge-type="2" style="display:inline"></div> </div> <div class="abstract hidden"> <p>The design of accurate helium-solute interaction potentials for the simulation of chemically complex molecules solvated in superfluid helium has long been a cumbersome task due to the rather weak but strongly anisotropic nature of the interactions. We show that this challenge can be met by using a combination of an effective pair potential for the He–He interactions and a flexible high-dimensional neural network potential (NNP) for describing the complex interaction between helium and the solute in a pairwise additive manner. This approach yields an excellent agreement with a mean absolute deviation as small as 0.04 kJ mol−1 for the interaction energy between helium and both hydronium and Zundel cations compared with coupled cluster reference calculations with an energetically converged basis set. The construction and improvement of the potential can be performed in a highly automated way, which opens the door for applications to a variety of reactive molecules to study the effect of solvation on the solu...</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Schran2018/10.1063/1.4996819</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schran, Christoph and Uhl, Felix and Behler, J{\"{o}}rg and Marx, Dominik}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1063/1.4996819}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{00219606}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{J. Chem. Phys.}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{102310}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{High-dimensional neural network potentials for solvation: The case of protonated water clusters in helium}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{148}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Christoph Schran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from Christoph Schran. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>